{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nebula/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got full_df\n",
      "got parsed_df\n",
      "got full_df\n",
      "got parsed_df\n"
     ]
    }
   ],
   "source": [
    "# do basic imports and unpack McMurdo data\n",
    "\n",
    "from pmagpy import ipmag\n",
    "reload(ipmag)\n",
    "from pmagpy import pmag\n",
    "from programs import new_builder as nb\n",
    "from programs import data_model3\n",
    "reload(data_model3)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from programs.new_builder import Contribution\n",
    "\n",
    "import pmagpy.controlled_vocabularies3 as cv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-W- No such file: /Users/nebula/Python/PmagPy/3_0/Megiddo/images.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations</th>\n",
       "      <th>lat_n</th>\n",
       "      <th>lat_s</th>\n",
       "      <th>location</th>\n",
       "      <th>location_type</th>\n",
       "      <th>lon_e</th>\n",
       "      <th>lon_w</th>\n",
       "      <th>dir_inc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tel Hazor</th>\n",
       "      <td>This study</td>\n",
       "      <td>33.0168</td>\n",
       "      <td>400</td>\n",
       "      <td>Tel Hazor</td>\n",
       "      <td>Archeological Site</td>\n",
       "      <td>35.568</td>\n",
       "      <td>35.568</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tel Megiddo</th>\n",
       "      <td>This study</td>\n",
       "      <td>32.585</td>\n",
       "      <td>32.585</td>\n",
       "      <td>Tel Megiddo</td>\n",
       "      <td>Archeological Site</td>\n",
       "      <td>35.185</td>\n",
       "      <td>35.185</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              citations    lat_n   lat_s     location       location_type  \\\n",
       "location                                                                    \n",
       "Tel Hazor    This study  33.0168     400    Tel Hazor  Archeological Site   \n",
       "Tel Megiddo  This study   32.585  32.585  Tel Megiddo  Archeological Site   \n",
       "\n",
       "              lon_e   lon_w  dir_inc  \n",
       "location                              \n",
       "Tel Hazor    35.568  35.568        5  \n",
       "Tel Megiddo  35.185  35.185        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = os.path.join(os.getcwd(), '3_0', 'Megiddo')\n",
    "con = Contribution(dir_path)\n",
    "\n",
    "loc_dm = con.tables['locations'].data_model.dm['locations']\n",
    "loc_df = con.tables['locations'].df\n",
    "site_dm = con.tables['sites'].data_model.dm['sites']\n",
    "site_df = con.tables['sites'].df\n",
    "samp_df = con.tables['samples'].df\n",
    "samp_dm = con.tables['samples'].data_model.dm['samples']\n",
    "spec_df = con.tables['specimens'].df\n",
    "spec_dm = con.tables['specimens'].data_model.dm['specimens']\n",
    "age_df = con.tables['ages'].df\n",
    "age_dm = con.tables['ages'].data_model.dm['ages']\n",
    "meas_df = con.tables['measurements'].df\n",
    "meas_dm = con.tables['measurements'].data_model.dm['measurements']\n",
    "cont_df = con.tables['contribution'].df\n",
    "cont_dm = con.tables['contribution'].data_model.dm['contribution']\n",
    "crit_df = con.tables['criteria'].df\n",
    "crit_dm = con.tables['criteria'].data_model.dm['criteria']\n",
    "\n",
    "\n",
    "current_con = con\n",
    "current_df = loc_df\n",
    "current_dm = loc_dm\n",
    "# replace NaN with None\n",
    "current_dm = current_dm.where((pd.notnull(current_dm)), None)\n",
    "cols = current_df.columns\n",
    "\n",
    "\n",
    "#vocab.get_controlled_vocabularies()\n",
    "\n",
    "# mess up some validations for locations\n",
    "current_df.loc['Tel Hazor']['lat_s'] = 400.\n",
    "current_df['dir_inc'] = 5\n",
    "current_con.tables.pop('sites')\n",
    "\n",
    "# mess up some validations for sites\n",
    "#current_df.pop('age')\n",
    "#current_df['dir_tilt_correction'] = 1\n",
    "#current_df['dir_tilt_correction'] = 'one'\n",
    "\n",
    "# mess up some validations for samples\n",
    "#current_df.pop('citations')\n",
    "#current_df.iloc[0].lon = 600.\n",
    "#current_df.iloc[1].lat = 'hello'\n",
    "\n",
    "# mess up some validations for measurements\n",
    "#current_df.loc['mgh05a01:LP-PI-TRM1', 'magn_moment'] = 2\n",
    "#current_df.loc['mgh05a01:LP-PI-TRM1', 'specimen'] = \"fake_specimen\"\n",
    "#current_df.pop('experiment')\n",
    "\n",
    "current_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Importing controlled vocabularies from https://earthref.org\n"
     ]
    }
   ],
   "source": [
    "import pmagpy.controlled_vocabularies3 as cv\n",
    "reload(cv)\n",
    "vocab = cv.Vocabulary()\n",
    "vocabulary, possible_vocabulary = vocab.get_controlled_vocabularies()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tel Hazor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tel Megiddo</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [Tel Hazor, Tel Megiddo]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check column validity\n",
    "invalid_cols = [col for col in cols if col not in current_dm.index]\n",
    "\n",
    "\n",
    "# need to add requiredOneInGroup\n",
    "\n",
    "def requiredUnless(col_name, df, arg, *args):\n",
    "    arg_list = arg.split(\",\")\n",
    "    arg_list = [arg.strip('\"') for arg in arg_list]\n",
    "    msg = \"\"\n",
    "    for a in arg_list:\n",
    "        if \".\" in a:\n",
    "            continue\n",
    "        if a not in df.columns:\n",
    "            msg += \"{} is required unless {} is present.  \".format(col_name, a)\n",
    "    if msg:\n",
    "        return msg\n",
    "    else:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def requiredUnlessTable(col_name, df, arg, *args):\n",
    "    \"\"\"\n",
    "    Col_name must be present in df unless\n",
    "    arg (table_name) is present in contribution\n",
    "    \"\"\"\n",
    "    table_name = arg\n",
    "    if col_name in df.columns:\n",
    "        return None\n",
    "    elif table_name in current_con.tables:\n",
    "        return None\n",
    "    else:\n",
    "        #print \"{} is required unless table {} is present\".format(col_name, table_name)\n",
    "        return \"{} is required unless table {} is present\".format(col_name, table_name)\n",
    "\n",
    "    \n",
    "def requiredIfGroup(col_name, df, arg, *args):\n",
    "    \"\"\"\n",
    "    Col_name is required if other columns of \n",
    "    the group arg are present.\n",
    "    \"\"\"\n",
    "    group_name = arg\n",
    "    groups = set()\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        if col not in current_dm.index:\n",
    "            continue\n",
    "        group = current_dm.loc[col]['group']\n",
    "        groups.add(group)\n",
    "    if group_name in groups:\n",
    "        if col_name in columns:\n",
    "            return None\n",
    "        else:\n",
    "            #print \"{} is required if column group {} is used\".format(col_name, group_name)\n",
    "            return \"{} is required if column group {} is used\".format(col_name, group_name)\n",
    "    return None\n",
    "\n",
    "\n",
    "def required(col_name, df, arg):\n",
    "    #print df\n",
    "    if col_name in df.columns:\n",
    "        return None\n",
    "    else:\n",
    "        return \"{} is required\".format(col_name) \n",
    "  \n",
    "def is_in(row, col_name, arg, *args):\n",
    "    cell_value = row[col_name]\n",
    "    if \".\" in arg:\n",
    "        table_name, table_col_name = arg.split(\".\")\n",
    "        if table_name not in current_con.tables:\n",
    "            return \"Must contain a value from {} table. Missing {} table.\".format(table_name, table_name)\n",
    "        possible_values = current_con.tables[table_name].df[table_col_name].unique()\n",
    "        if cell_value not in possible_values:\n",
    "            return \"This value: {} is not found in: {}\".format(cell_value, arg)\n",
    "    return None\n",
    "    \n",
    "def check_max(row, col_name, arg, *args):\n",
    "    #print 'check_max'\n",
    "    cell_value = row[col_name]\n",
    "    if not cell_value:\n",
    "        return None\n",
    "    try:\n",
    "        arg = float(arg)\n",
    "    except ValueError:\n",
    "        arg = row[arg]\n",
    "    arg = float(arg)\n",
    "    try:\n",
    "        if float(cell_value) <= float(arg):\n",
    "            return None\n",
    "        else:\n",
    "            return \"{} must be <= {}\".format(str(cell_value), str(arg))\n",
    "    # this happens when the value isn't a float (an error which will be caught elsewhere)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def check_min(row, col_name, arg, *args):\n",
    "    cell_value = row[col_name]\n",
    "    if not cell_value:\n",
    "        return None\n",
    "    try:\n",
    "        arg = float(arg)\n",
    "    except ValueError:\n",
    "        arg = row[arg]\n",
    "    try:\n",
    "        if float(cell_value) >= float(arg):\n",
    "            return None\n",
    "        else:\n",
    "            return \"{} must be >= {}\".format(str(cell_value), str(arg))\n",
    "    # this happens when the value isn't a float (an error which will be caught elsewhere)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def cv(row, col_name, arg, current_data_model):\n",
    "    cell_value = row[col_name]\n",
    "    if not cell_value:\n",
    "        return None\n",
    "    if cell_value.lower() in [v.lower() for v in vocabulary[col_name]]:\n",
    "        return None\n",
    "    else:\n",
    "        return \"{} is not in {}\".format(cell_value, arg)\n",
    "        \n",
    "\n",
    "# validate presence\n",
    "presence_operations = {\"required\": required, \"requiredUnless\": requiredUnless,\n",
    "                       \"requiredIfGroup\": requiredIfGroup, \n",
    "                       'requiredUnlessTable': requiredUnlessTable}\n",
    "# validate values\n",
    "value_operations = {\"max\": check_max, \"min\": check_min, \"cv\": cv, \"in\": is_in}\n",
    "\n",
    "def split_func(string):\n",
    "    \"\"\"\n",
    "    Take a string like 'requiredIf(\"arg_name\")'\n",
    "    return the function name and the argument:\n",
    "    (requiredIf, arg_name)\n",
    "    \"\"\"\n",
    "    ind = string.index(\"(\")\n",
    "    return string[:ind], string[ind+1:-1].strip('\"')\n",
    "\n",
    "\n",
    "def test_type(value, value_type):\n",
    "    if not value:\n",
    "        return None\n",
    "    if value_type == \"String\":\n",
    "        if str(value) == value:\n",
    "            return None\n",
    "        else:\n",
    "            return \"should be string\"\n",
    "    elif value_type == \"Number\":\n",
    "        try:\n",
    "            float(value)\n",
    "            return None\n",
    "        except ValueError:\n",
    "            return \"should be a number\"\n",
    "    elif value_type == \"Integer\":\n",
    "        if isinstance(value, str):\n",
    "            if str(int(value)) == value:\n",
    "                return None\n",
    "            else:\n",
    "                return \"should be an integer\"\n",
    "        else:\n",
    "            if int(value) == value:\n",
    "                return None\n",
    "            else:\n",
    "                return \"should be an integer\"\n",
    "    else:\n",
    "        return None\n",
    "    #String, Number, Integer, List, Matrix, Dictionary, Text\n",
    "    \n",
    "\n",
    "\n",
    "def validate_df(df, dm):\n",
    "    for validation_name, validation in dm.iterrows():\n",
    "        value_type = validation['type']\n",
    "        #print 'value_type', value_type\n",
    "        if validation_name in df.columns:\n",
    "            output = df[validation_name].apply(test_type, args=(value_type,))\n",
    "            df[\"type_\" + validation_name] = output\n",
    "\n",
    "        val_list = validation['validations']\n",
    "        if not val_list:\n",
    "            continue\n",
    "        for num, val in enumerate(val_list):\n",
    "            func_name, arg = split_func(val)\n",
    "            # first validate for presence\n",
    "            if func_name in presence_operations:\n",
    "                func = presence_operations[func_name]\n",
    "                grade = func(validation_name, current_df, arg)\n",
    "                pass_col_name = \"presence_pass_\" + validation_name + \"_\" + func.__name__\n",
    "                df[pass_col_name] = grade\n",
    "    \n",
    "            # then validate for correct values\n",
    "            elif func_name in value_operations:\n",
    "                func = value_operations[func_name]\n",
    "                if validation_name in df.columns:\n",
    "                    grade = df.apply(func, args=(validation_name, arg, dm), axis=1)\n",
    "                    df[\"pass_\" + validation_name + \"_\" + func.__name__] = grade.astype(object)\n",
    "    return df\n",
    "\n",
    "                \n",
    "current_df = validate_df(current_df, current_dm)\n",
    "\n",
    "    \n",
    "# check that values pass validation\n",
    "# validation checks to add:\n",
    "# sv (suggested vocab)\n",
    "# requiredOneInGroup\n",
    "\n",
    "\n",
    "# re-do upload_magic to use contribution-level (??)\n",
    "\n",
    "# first, do validations on each table in the contribution\n",
    "# this will include removing unneeded data (RmKeys from old upload_magic)\n",
    "# this will also include checking everything against the data model (strings are strings, etc.)g\n",
    "\n",
    "# next, do cross-contribution validations (all specimens exist, etc.)\n",
    "\n",
    "# next, splat out each table into a file and wrap it up.  give it a sensible name.  \n",
    "\n",
    "pass_cols = current_df.columns.str.match(\"^pass_\")\n",
    "present_cols = current_df.columns.str.match(\"^presen\")\n",
    "type_cols = current_df.columns.str.match(\"^type_\")\n",
    "val_cols = np.where([bool(v) for v in pass_cols], [bool(v) for v in pass_cols], [bool(v) for v in present_cols])\n",
    "\n",
    "present_col_names = current_df.columns[present_cols]\n",
    "current_df[present_col_names].dropna(how='all', axis=1).head()\n",
    "\n",
    "current_df[current_df.columns[type_cols]].dropna(how='all', axis=1).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>presence_pass_age_requiredUnless</th>\n",
       "      <th>presence_pass_age_high_requiredUnless</th>\n",
       "      <th>presence_pass_age_low_requiredUnless</th>\n",
       "      <th>presence_pass_age_unit_required</th>\n",
       "      <th>presence_pass_dir_dec_requiredIfGroup</th>\n",
       "      <th>presence_pass_dir_tilt_correction_requiredIfGroup</th>\n",
       "      <th>presence_pass_geologic_classes_required</th>\n",
       "      <th>presence_pass_lithologies_required</th>\n",
       "      <th>presence_pass_method_codes_requiredUnlessTable</th>\n",
       "      <th>presence_pass_result_quality_requiredUnlessTable</th>\n",
       "      <th>presence_pass_result_type_requiredUnlessTable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tel Hazor</th>\n",
       "      <td>age is required unless age_low is present.  ag...</td>\n",
       "      <td>age_high is required unless age is present.</td>\n",
       "      <td>age_low is required unless age is present.</td>\n",
       "      <td>age_unit is required</td>\n",
       "      <td>dir_dec is required if column group Direction ...</td>\n",
       "      <td>dir_tilt_correction is required if column grou...</td>\n",
       "      <td>geologic_classes is required</td>\n",
       "      <td>lithologies is required</td>\n",
       "      <td>method_codes is required unless table sites is...</td>\n",
       "      <td>result_quality is required unless table sites ...</td>\n",
       "      <td>result_type is required unless table sites is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tel Megiddo</th>\n",
       "      <td>age is required unless age_low is present.  ag...</td>\n",
       "      <td>age_high is required unless age is present.</td>\n",
       "      <td>age_low is required unless age is present.</td>\n",
       "      <td>age_unit is required</td>\n",
       "      <td>dir_dec is required if column group Direction ...</td>\n",
       "      <td>dir_tilt_correction is required if column grou...</td>\n",
       "      <td>geologic_classes is required</td>\n",
       "      <td>lithologies is required</td>\n",
       "      <td>method_codes is required unless table sites is...</td>\n",
       "      <td>result_quality is required unless table sites ...</td>\n",
       "      <td>result_type is required unless table sites is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              presence_pass_age_requiredUnless  \\\n",
       "location                                                         \n",
       "Tel Hazor    age is required unless age_low is present.  ag...   \n",
       "Tel Megiddo  age is required unless age_low is present.  ag...   \n",
       "\n",
       "                     presence_pass_age_high_requiredUnless  \\\n",
       "location                                                     \n",
       "Tel Hazor    age_high is required unless age is present.     \n",
       "Tel Megiddo  age_high is required unless age is present.     \n",
       "\n",
       "                     presence_pass_age_low_requiredUnless  \\\n",
       "location                                                    \n",
       "Tel Hazor    age_low is required unless age is present.     \n",
       "Tel Megiddo  age_low is required unless age is present.     \n",
       "\n",
       "            presence_pass_age_unit_required  \\\n",
       "location                                      \n",
       "Tel Hazor              age_unit is required   \n",
       "Tel Megiddo            age_unit is required   \n",
       "\n",
       "                         presence_pass_dir_dec_requiredIfGroup  \\\n",
       "location                                                         \n",
       "Tel Hazor    dir_dec is required if column group Direction ...   \n",
       "Tel Megiddo  dir_dec is required if column group Direction ...   \n",
       "\n",
       "             presence_pass_dir_tilt_correction_requiredIfGroup  \\\n",
       "location                                                         \n",
       "Tel Hazor    dir_tilt_correction is required if column grou...   \n",
       "Tel Megiddo  dir_tilt_correction is required if column grou...   \n",
       "\n",
       "            presence_pass_geologic_classes_required  \\\n",
       "location                                              \n",
       "Tel Hazor              geologic_classes is required   \n",
       "Tel Megiddo            geologic_classes is required   \n",
       "\n",
       "            presence_pass_lithologies_required  \\\n",
       "location                                         \n",
       "Tel Hazor              lithologies is required   \n",
       "Tel Megiddo            lithologies is required   \n",
       "\n",
       "                presence_pass_method_codes_requiredUnlessTable  \\\n",
       "location                                                         \n",
       "Tel Hazor    method_codes is required unless table sites is...   \n",
       "Tel Megiddo  method_codes is required unless table sites is...   \n",
       "\n",
       "              presence_pass_result_quality_requiredUnlessTable  \\\n",
       "location                                                         \n",
       "Tel Hazor    result_quality is required unless table sites ...   \n",
       "Tel Megiddo  result_quality is required unless table sites ...   \n",
       "\n",
       "                 presence_pass_result_type_requiredUnlessTable  \n",
       "location                                                        \n",
       "Tel Hazor    result_type is required unless table sites is ...  \n",
       "Tel Megiddo  result_type is required unless table sites is ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_df[current_df.columns[present_cols]].dropna(how='all', axis=1).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pass_lat_n_check_min</th>\n",
       "      <th>pass_lat_s_check_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tel Hazor</th>\n",
       "      <td>33.0168 must be &gt;= 400.0</td>\n",
       "      <td>400.0 must be &lt;= 33.0168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tel Megiddo</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pass_lat_n_check_min      pass_lat_s_check_max\n",
       "location                                                       \n",
       "Tel Hazor    33.0168 must be >= 400.0  400.0 must be <= 33.0168\n",
       "Tel Megiddo                      None                      None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_df[current_df.columns[pass_cols]].dropna(how='all', axis=1).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tel Hazor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tel Megiddo</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [Tel Hazor, Tel Megiddo]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_df[current_df.columns[type_cols]].dropna(how='all', axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in an existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>five</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   one  two  three  four  five\n",
       "0    4  NaN    1.0     9     1\n",
       "1    9  8.0    6.0     7     9\n",
       "2    6  4.0    NaN     2     4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep all of df1, add in any extra from df2\n",
    "df1 = pd.DataFrame(np.random.randint(1, 10, (3, 5)), columns=['one', 'two', 'three', 'four', 'five'])\n",
    "df1.iloc[0, 1] = np.nan\n",
    "df1.iloc[2, 2] = np.nan\n",
    "df2 = pd.DataFrame(np.random.randint(1, 10, (3, 5)), columns=['one', 'three', 'five', 'seven', 'nine'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>three</th>\n",
       "      <th>five</th>\n",
       "      <th>seven</th>\n",
       "      <th>nine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   one  three  five  seven  nine\n",
       "0    5      4     1      7     2\n",
       "1    7      9     8      9     1\n",
       "2    1      7     7      5     9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>five</th>\n",
       "      <th>nine</th>\n",
       "      <th>seven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   one  two  three  four  five  nine  seven\n",
       "0    4  NaN    1.0     9     1     2      7\n",
       "1    9  8.0    6.0     7     9     1      9\n",
       "2    6  4.0    7.0     2     4     9      5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df2_cols = df2.columns.difference(df1.columns)\n",
    "unique_df2 = df2[unique_df2_cols]\n",
    "\n",
    "# this adds in all the unique columns that weren't in df1\n",
    "concat_df = pd.concat([df1, unique_df2], axis=1)\n",
    "# fills in null values in df1 with values from df2\n",
    "concat_df.fillna(df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
